{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data compression\n",
    "\n",
    "*legend-pydataobj* gives the user a lot of flexibility in choosing how to compress LGDOs, on disk or in memory, through traditional HDF5 filters or custom waveform compression algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lgdo\n",
    "from lgdo import lh5\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Let's start by creating a dummy LGDO Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lgdo.Table(\n",
    "    size=1000,\n",
    "    col_dict={\n",
    "        \"col1\": lgdo.Array(np.arange(0, 100, 0.1)),\n",
    "        \"col2\": lgdo.Array(np.random.rand(1000)),\n",
    "    },\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "and writing it to disk with default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh5.write(data, \"data\", \"data.lh5\", wo_mode=\"of\")\n",
    "lh5.show(\"data.lh5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Let's inspect the data on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "def show_h5ds_opts(obj):\n",
    "    with h5py.File(\"data.lh5\") as f:\n",
    "        print(obj)\n",
    "        for attr in [\"compression\", \"compression_opts\", \"shuffle\", \"chunks\"]:\n",
    "            print(\">\", attr, \":\", f[obj].__getattribute__(attr))\n",
    "        print(\"> size :\", f[obj].id.get_storage_size(), \"B\")\n",
    "\n",
    "\n",
    "show_h5ds_opts(\"data/col1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Looks like the data is compressed with [Gzip](http://www.gzip.org) (compression level 4) by default! This default setting is stored in the global `DEFAULT_HDF5_SETTINGS` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh5.DEFAULT_HDF5_SETTINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Which specifies the default keyword arguments forwarded to [h5py.Group.create_dataset()](https://docs.h5py.org/en/stable/high/group.html#h5py.Group.create_dataset) and can be overridden by the user\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use another built-in filter\n",
    "lh5.DEFAULT_HDF5_SETTINGS = {\"compression\": \"lzf\"}\n",
    "\n",
    "# specify filter name and options\n",
    "lh5.DEFAULT_HDF5_SETTINGS = {\"compression\": \"gzip\", \"compression_opts\": 7}\n",
    "\n",
    "# specify a registered filter provided by hdf5plugin\n",
    "import hdf5plugin\n",
    "\n",
    "lh5.DEFAULT_HDF5_SETTINGS = {\"compression\": hdf5plugin.Blosc()}\n",
    "\n",
    "# shuffle bytes before compressing (typically better compression ratio with no performance penalty)\n",
    "lh5.DEFAULT_HDF5_SETTINGS = {\"shuffle\": True, \"compression\": \"lzf\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Useful resources and lists of HDF5 filters:\n",
    "\n",
    "- [Registered HDF5 filters](https://confluence.hdfgroup.org/display/support/HDF5+Filter+Plugins)\n",
    "- [Built-in HDF5 filters from h5py](https://docs.h5py.org/en/stable/high/dataset.html#filter-pipeline)\n",
    "- [Extra filters from hdf5plugin](https://hdf5plugin.readthedocs.io/en/stable/usage.html)\n",
    "\n",
    "Let's now re-write the data with the updated default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh5.write(data, \"data\", \"data.lh5\", wo_mode=\"of\")\n",
    "show_h5ds_opts(\"data/col1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Nice. Shuffling bytes before compressing significantly reduced size on disk. Last but not least, `create_dataset()` keyword arguments can be passed to `write()`. They will be forwarded as is, overriding default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh5.write(data, \"data\", \"data.lh5\", wo_mode=\"of\", shuffle=True, compression=\"gzip\")\n",
    "show_h5ds_opts(\"data/col1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Object-specific compression settings are supported via the `hdf5_settings` LGDO attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"col2\"].attrs[\"hdf5_settings\"] = {\"compression\": \"gzip\"}\n",
    "lh5.write(data, \"data\", \"data.lh5\", wo_mode=\"of\")\n",
    "\n",
    "show_h5ds_opts(\"data/col1\")\n",
    "show_h5ds_opts(\"data/col2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "We are now storing table columns with different compression settings.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Note:** since any [h5py.Group.create_dataset()](https://docs.h5py.org/en/stable/high/group.html#h5py.Group.create_dataset) keyword argument can be used in `write()` or set in the `hdf5_settings` attribute, other HDF5 dataset settings can be configured, like the chunk size.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh5.write(data, \"data\", \"data.lh5\", wo_mode=\"of\", chunks=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Waveform compression\n",
    "\n",
    "*legend-pydataobj* implements fast custom waveform compression routines in the [lgdo.compression](https://legend-pydataobj.readthedocs.io/en/stable/api/lgdo.compression.html) subpackage.\n",
    "\n",
    "Let's try them out on some waveform test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from legendtestdata import LegendTestData\n",
    "\n",
    "ldata = LegendTestData()\n",
    "wfs = lh5.read(\n",
    "    \"geds/raw/waveform\",\n",
    "    ldata.get_path(\"lh5/LDQTA_r117_20200110T105115Z_cal_geds_raw.lh5\"),\n",
    ")\n",
    "wfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Let's encode the waveform values with the [RadwareSigcompress](https://legend-pydataobj.readthedocs.io/en/stable/api/lgdo.compression.html#lgdo.compression.radware.RadwareSigcompress) codec.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Note:** samples from these test waveforms must be shifted by -32768 for compatibility reasons, see [lgdo.compression.radware.encode()](https://legend-pydataobj.readthedocs.io/en/stable/api/lgdo.compression.html#lgdo.compression.radware.encode).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lgdo.compression import encode, RadwareSigcompress\n",
    "\n",
    "enc_values = encode(wfs.values, RadwareSigcompress(codec_shift=-32768))\n",
    "enc_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "The output LGDO is an [ArrayOfEncodedEqualSizedArrays](https://legend-pydataobj.readthedocs.io/en/stable/api/lgdo.types.html#lgdo.types.encoded.ArrayOfEncodedEqualSizedArrays), which is basically an array of bytes representing the compressed data. How big is this compressed object in bytes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_values.encoded_data.flattened_data.nda.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "How big was the original data structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs.values.nda.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "It shrank quite a bit!\n",
    "\n",
    "Let's now make a `WaveformTable` object wrapping these encoded values, instead of the uncompressed ones, and dump it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wfs = lgdo.WaveformTable(\n",
    "    values=enc_values,\n",
    "    t0=wfs.t0,\n",
    "    dt=wfs.dt,\n",
    ")\n",
    "lh5.write(enc_wfs, \"waveforms\", \"data.lh5\", wo_mode=\"o\")\n",
    "lh5.show(\"data.lh5\", attrs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "The LH5 structure is more complex now. Note how the compression settings are stored as HDF5 attributes.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Warning:** HDF5 compression is never applied to waveforms compressed with these custom filters.\n",
    "</div>\n",
    "\n",
    "Let's try to read the data back in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = lh5.read(\"waveforms\", \"data.lh5\")\n",
    "obj.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Wait, this is not the compressed data we just wrote to disk, it got decompressed on the fly! It's still possible to just return the compressed data though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = lh5.read(\"waveforms\", \"data.lh5\", decompress=False)\n",
    "obj.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "And then decompress it manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lgdo.compression import decode\n",
    "\n",
    "decode(obj.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Waveform compression settings can also be specified at the LGDO level by attaching a `compression` attribute to the `values` attribute of a `WaveformTable` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lgdo.compression import ULEB128ZigZagDiff\n",
    "\n",
    "wfs.values.attrs[\"compression\"] = ULEB128ZigZagDiff()\n",
    "lh5.write(wfs, \"waveforms\", \"data.lh5\", wo_mode=\"of\")\n",
    "\n",
    "obj = lh5.read(\"waveforms\", \"data.lh5\", decompress=False)\n",
    "obj.values.attrs[\"codec\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Further reading:\n",
    "\n",
    "- [Available waveform compression algorithms](https://legend-pydataobj.readthedocs.io/en/stable/api/lgdo.compression.html)\n",
    "- [read() docstring](https://legend-pydataobj.readthedocs.io/en/stable/api/lgdo.html#lgdo.lh5.store.LH5Store.read)\n",
    "- [write() docstring](https://legend-pydataobj.readthedocs.io/en/stable/api/lgdo.html#lgdo.lh5_store.LH5Store.write)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
